{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **lenet-5 and alexnet Assignment**"
      ],
      "metadata": {
        "id": "qFk7PipGSazz"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KHu65L7HSRw7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Q1. Explain the achitecture of LeNet-5 and its significance in the field of deep learning."
      ],
      "metadata": {
        "id": "KVpAv6m9Skzj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### **LeNet-5 Architecture**  \n",
        "Proposed by Yann LeCun in 1998, LeNet-5 is a pioneering convolutional neural network (CNN) designed for handwritten digit recognition (MNIST dataset). It consists of **7 layers (excluding input)**, with alternating convolutional, pooling, and fully connected layers.  \n",
        "\n",
        "1. **Input Layer**:  \n",
        "   - The input to LeNet-5 is an image of size 32x32 pixels in grayscale, so the input has dimensions\n",
        "   (32x32x1).\n",
        "   Originally, the MNIST dataset images were 28x28 pixels, but they were zero-padded to 32x32 to\n",
        "   fit the network's design.\n",
        "\n",
        "   - Note : 32x32 grayscale image (MNIST images padded from 28x28).  \n",
        "\n",
        "2. **C1 - Convolutional Layer**:  \n",
        "   - The first layer is a convolutional layer that applies 6 convolutional filters (kernels) of size\n",
        "   5x5 with a stride of 1.\n",
        "   - The output of this layer is 6 feature maps of size 28x28 (since 32-5+1=28).\n",
        "   - Activation function used: sigmoid (in the original implementation), though nowadays ReLU is\n",
        "   more commonly used.\n",
        "   - Note: 6 filters (5x5), stride 1 → Output: 28x28x6(since 32-5+1=28).  \n",
        "\n",
        "3. **S2 - Subsampling (Pooling) Layer**:  \n",
        "   - The second layer is a subsampling layer (also called a pooling layer), specifically using\n",
        "   average pooling (2x2 pooling window with a stride of 2).\n",
        "   - This reduces the spatial dimensions of each feature map by a factor of 2.\n",
        "   - After this layer, the output is 6 feature maps of size 14x14.\n",
        "   - Note: Average pooling (2x2), stride 2 → Output: 14x14x6.  \n",
        "\n",
        "4. **C3 - Convolutional Layer**:  \n",
        "   - The third layer is another convolutional layer with 16 filters of size 5x5.\n",
        "   However, not all of the 6 input feature maps are connected to all of the 16 output feature maps.\n",
        "   - The connections form a sparse connection pattern: each of the 16 feature maps in the third\n",
        "   layer is connected to a subset of the feature maps from the previous layer.\n",
        "   - The output feature maps have size 10x10.\n",
        "   - Note: 16 filters (5x5), sparse connections → Output: 10x10x16.  \n",
        "\n",
        "5. **S4 - Subsampling (Pooling) Layer**:  \n",
        "    - Similar to Layer 2, this is another subsampling (pooling) layer that uses average pooling\n",
        "   with a 2x2 filter and stride of 2.\n",
        "   - The output size is reduced to 5x5 for each of the 16 feature maps.\n",
        "   - Note: Average pooling (2x2), stride 2 → Output: 5x5x16.  \n",
        "\n",
        "6. **C5 - Fully Connected Layer**:  \n",
        "   - This layer is a fully connected layer (also called a dense layer), with 120 neurons.\n",
        "   - The 16 input feature maps from the previous layer are flattened into a 1D vector of size 400\n",
        "   (16 * 5 * 5 = 400), and this vector is passed to the 120 neurons.\n",
        "   - Note: 120 neurons, input flattened (400).  \n",
        "\n",
        "7. **F6 - Fully Connected Layer**:  \n",
        "   - This is another fully connected layer with 84 neurons.\n",
        "   - The output is a 1D vector of size 84.\n",
        "   - Note: 84 neurons.  \n",
        "\n",
        "8. **Output Layer**:  \n",
        "   - The final layer is another fully connected layer, which outputs a 10-dimensional vector\n",
        "   corresponding to the 10 possible classes (0-9 for MNIST digit recognition).\n",
        "   - A softmax activation is applied to get the probabilities for each class.\n",
        "\n",
        "   - Note: 10 neurons with softmax for classification.\n",
        "\n",
        "---\n",
        "### Key Components of LeNet-5 (Simplified)\n",
        "\n",
        "1. **Convolutional Layers (C1, C3)**:  \n",
        "   - Extract spatial features like edges and patterns via convolution.  \n",
        "\n",
        "2. **Pooling Layers (S2, S4)**:  \n",
        "   - Reduce spatial dimensions, prevent overfitting, and provide translational invariance.  \n",
        "\n",
        "3. **Fully Connected Layers (C5, F6)**:  \n",
        "   - Combine extracted features for final classification into 10 classes.  \n",
        "---\n",
        "   \n",
        "### **Significance in Deep Learning**  \n",
        "\n",
        "1. **Pioneering CNNs**:  \n",
        "   - Introduced core concepts of convolution, pooling, and hierarchical feature extraction.  \n",
        "\n",
        "2. **End-to-End Learning**:  \n",
        "   - Demonstrated the power of training models directly on raw data using backpropagation.  \n",
        "\n",
        "3. **Foundation for Modern CNNs**:  \n",
        "   - Inspired architectures like AlexNet, VGG, and ResNet, building on its principles.  \n",
        "\n",
        "4. **Efficiency**:  \n",
        "   - Early example of implementing deep learning on limited hardware.  \n",
        "\n",
        "5. **Applications**:  \n",
        "   - Solved practical tasks like handwritten digit recognition, proving the utility of deep learning in computer vision.  \n",
        "\n",
        "---\n",
        "\n",
        "### **Key Contributions**  \n",
        "- Established the effectiveness of CNNs for visual tasks.  \n",
        "- Highlighted the importance of convolution and pooling for spatial invariance.  \n",
        "- Sparked advancements in optimizing deep learning for hardware.  \n",
        "\n"
      ],
      "metadata": {
        "id": "snGXJ2WVUxR9"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_h22uXd3SR9S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Q2. Describe the key components of LeNet-5 and their roles in the network."
      ],
      "metadata": {
        "id": "btoIKCLES6CH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**LeNet-5** has seven layers (excluding the input layer) and is composed of both convolutional and fully connected layers.\n",
        "\n",
        "### **Key Components of LeNet-5 and Their Roles**  \n",
        "\n",
        "1. **Convolutional Layers (C1, C3)**:  \n",
        "   - **C1**: 6 filters (5x5) → Output: 28x28 feature maps.  \n",
        "   - **C3**: 16 filters (5x5) → Output: 10x10 feature maps.  \n",
        "   - **Role**: Extract hierarchical features like edges, textures, and patterns.  \n",
        "\n",
        "2. **Pooling Layers (S2, S4)**:  \n",
        "   - **S2**: Average pooling (2x2) → Output: 14x14.  \n",
        "   - **S4**: Average pooling (2x2) → Output: 5x5.  \n",
        "   - **Role**: Reduce spatial dimensions, retain key features, and improve translational invariance.  \n",
        "\n",
        "3. **Fully Connected Layers (C5, F6)**:  \n",
        "   - **C5**: 120 neurons, input flattened to 400 values.  \n",
        "   - **F6**: 84 neurons.  \n",
        "   - **Role**: Integrate features and prepare them for classification.  \n",
        "\n",
        "4. **Output Layer**:  \n",
        "   - **10 neurons** (for MNIST digits 0-9).  \n",
        "   - **Role**: Generate probabilities using softmax and classify the image.  \n",
        "\n"
      ],
      "metadata": {
        "id": "0lKkYW7lZaFw"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cnZNs1mmSSRE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Q3. Discuss the limitations of LeNet-5 and how subsequent architectures like AlexNet addressed these limitations."
      ],
      "metadata": {
        "id": "DNv5mNnRTGKT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### **Limitations of LeNet-5**  \n",
        "1. **Shallow Architecture**: Only 7 layers, limiting its ability to learn complex features.  \n",
        "2. **Small Input Size**: Designed for 32x32 grayscale images, unsuitable for high-resolution data.  \n",
        "3. **Limited Dataset**: Trained on MNIST, which is simple compared to modern datasets like ImageNet.  \n",
        "4. **Hardware Constraints**: Lacked GPU support, resulting in slow training.  \n",
        "5. **Activation Function**: Used sigmoid, prone to vanishing gradient issues in deeper networks.  \n",
        "\n",
        "---\n",
        "\n",
        "### **How AlexNet Addressed These Limitations**  \n",
        "1. **Deeper Architecture**: Added more layers (8 total) for better feature learning.  \n",
        "2. **Large Input Size**: Scaled to 227x227 RGB images for high-resolution data.  \n",
        "3. **Large Dataset**: Trained on ImageNet, leveraging millions of labeled images for better generalization.  \n",
        "4. **GPU Utilization**: Used GPUs for efficient training, enabling deeper and faster networks.  \n",
        "5. **ReLU Activation**: Replaced sigmoid with ReLU, speeding up training and mitigating vanishing gradients.  \n",
        "\n"
      ],
      "metadata": {
        "id": "SvvCR4ODagPJ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZW3m9tXcTbQh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Q4. Explain the architecture of AlexNet and its contributions to the advancement of deep learning."
      ],
      "metadata": {
        "id": "pYt8mNjaTeS3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "AlexNet, developed by Alex Krizhevsky et al. , Ilya Sutskever, and Geoffrey Hinton in 2012, was a landmark model in the history of deep learning. It achieved state-of-the-art performance on the ImageNet Large Scale Visual Recognition Challenge (ILSVRC) and marked a significant leap in the use of deep learning for large-scale image classification.\n",
        "\n",
        "### **AlexNet Architecture**\n",
        "1. **Input Layer**: 227x227x3 RGB images.  \n",
        "2. **Convolutional Layers**:  \n",
        "   - **Conv1**: 96 filters (11x11, stride 4) followed by max pooling.  \n",
        "   - **Conv2**: 256 filters (5x5) with max pooling.  \n",
        "   - **Conv3, Conv4, Conv5**: 384, 384, and 256 filters (3x3).  \n",
        "3. **Fully Connected Layers**:  \n",
        "   - 2 layers with 4096 neurons each, followed by ReLU activation and dropout.  \n",
        "4. **Output Layer**: Softmax layer with 1000 neurons for ImageNet classification.\n",
        "\n",
        "---\n",
        "\n",
        "### **Contributions of AlexNet**\n",
        "1. **Breakthrough Performance**: Won the 2012 ImageNet Challenge with a top-5 error rate of 16.4%, far surpassing traditional methods.  \n",
        "2. **ReLU Activation**: Introduced ReLU, enabling faster training and mitigating vanishing gradients.  \n",
        "3. **GPU Utilization**: Pioneered multi-GPU training, significantly accelerating computation.  \n",
        "4. **Regularization Techniques**:  \n",
        "   - **Dropout**: Reduced overfitting in fully connected layers.  \n",
        "   - **Data Augmentation**: Used random cropping, flipping, and color jittering to improve generalization.  \n",
        "5. **Scalable Design**: Demonstrated deep networks’ ability to handle large datasets like ImageNet.  \n",
        "\n",
        "---\n",
        "\n",
        "### **Impact**\n",
        "- Set the foundation for modern deep learning in computer vision.  \n",
        "- Inspired architectures like VGG, GoogLeNet, and ResNet by showcasing the effectiveness of deep convolutional networks trained on GPUs with large datasets.\n",
        "\n"
      ],
      "metadata": {
        "id": "lHAccwvSb6ZG"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zX_b_cTZTro1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Q5. Compare and contrast the architectures of LeNet-5 and AlexNet. Discuss their similarities, difference and respective contributions to the field of deep learning."
      ],
      "metadata": {
        "id": "125fBKT8Tsv9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### **Comparison of LeNet-5 and AlexNet**\n",
        "\n",
        "#### **Similarities**  \n",
        "1. **Convolutional Architecture**: Both use convolutional layers to extract hierarchical features from images.  \n",
        "2. **Pooling Layers**: Employ pooling (average in LeNet-5, max in AlexNet) to reduce spatial dimensions and retain key features.  \n",
        "3. **Fully Connected Layers**: Both use fully connected layers at the end for classification tasks.  \n",
        "4. **End-to-End Training**: Both architectures use backpropagation for end-to-end learning.  \n",
        "\n",
        "---\n",
        "\n",
        "#### **Differences**  \n",
        "1. **Scale of Input**:  \n",
        "   - **LeNet-5**: Designed for 32x32 grayscale images (MNIST).  \n",
        "   - **AlexNet**: Handles 227x227 RGB images (ImageNet), enabling large-scale, complex tasks.  \n",
        "\n",
        "2. **Depth**:  \n",
        "   - **LeNet-5**: Shallow with 2 convolutional and 2 pooling layers.  \n",
        "   - **AlexNet**: Deeper with 5 convolutional layers, 3 fully connected layers, and more filters for hierarchical learning.  \n",
        "\n",
        "3. **Activation Function**:  \n",
        "   - **LeNet-5**: Sigmoid or tanh (prone to vanishing gradients).  \n",
        "   - **AlexNet**: ReLU, enabling faster training and mitigating vanishing gradients.  \n",
        "\n",
        "4. **Dataset**:  \n",
        "   - **LeNet-5**: Suited for small datasets like MNIST.  \n",
        "   - **AlexNet**: Trained on ImageNet with millions of high-resolution images.  \n",
        "\n",
        "5. **Hardware**:  \n",
        "   - **LeNet-5**: Trained on simple hardware.  \n",
        "   - **AlexNet**: Leveraged GPUs for parallel processing, making deep networks feasible.  \n",
        "\n",
        "6. **Regularization**:  \n",
        "   - **LeNet-5**: No dropout or data augmentation.  \n",
        "   - **AlexNet**: Introduced dropout and extensive data augmentation to prevent overfitting.  \n",
        "\n",
        "---\n",
        "\n",
        "#### **Contributions to Deep Learning**  \n",
        "- **LeNet-5**: Pioneered CNNs, introducing concepts like convolution, pooling, and hierarchical feature extraction, paving the way for deep learning in computer vision.  \n",
        "- **AlexNet**: Revolutionized deep learning by demonstrating the effectiveness of deep networks, large-scale datasets, GPUs, ReLU activation, and dropout. It triggered the modern deep learning era, influencing architectures like VGG, GoogLeNet, and ResNet.  \n",
        "\n"
      ],
      "metadata": {
        "id": "uvrkwj1kiovX"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "90xfwoHuTbhf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eIcLHDGdSSXx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}